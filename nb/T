from langchain_core.messages import HumanMessage, ToolMessage
from langchain_community.chat_models import ChatOllama
from langchain_core.tools import tool
from langgraph.graph import StateGraph, END
from typing import Annotated, Sequence
import operator

# Define tools
@tool
def calculator(expression: str) -> str:
    """Calculate mathematical expressions"""
    try:
        result = eval(expression)
        return str(result)
    except:
        return "Error in calculation"

# Initialize model with tool support
llm = ChatOllama(model="mistral")
tools = [calculator]
llm_with_tools = llm.bind_tools(tools)

# Agent state
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]

# Agent node function
def call_model(state: AgentState):
    messages = state["messages"]
    response = llm_with_tools.invoke(messages)
    
    # Check if tools were called
    if hasattr(response, 'tool_calls') and response.tool_calls:
        return {"messages": [response]}
    else:
        return {"messages": [response]}

# Tool node function
def call_tools(state: AgentState):
    messages = state["messages"]
    # Execute tools based on the last message
    # ... tool execution logic
    pass

# Build graph
workflow = StateGraph(AgentState)
workflow.add_node("agent", call_model)
workflow.add_node("tools", call_tools)
# ... add edges
